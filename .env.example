# LLM Provider Configuration
# Options: ollama (free, local), groq (free API), openai (paid)
LLM_PROVIDER=ollama

# Model name based on provider
# For Ollama: llama3.2, llama3.1, mistral, phi3, etc.
# For Groq: llama-3.1-70b-versatile, mixtral-8x7b-32768, etc.
# For OpenAI: gpt-4o, gpt-4-turbo, gpt-3.5-turbo, etc.
LLM_MODEL=llama3.2

# API Keys (only needed for respective providers)
# OpenAI API Key (get from https://platform.openai.com/api-keys)
OPENAI_API_KEY=your-openai-api-key-here

# Groq API Key (get free from https://console.groq.com/keys)
GROQ_API_KEY=your-groq-api-key-here

# Note: Ollama doesn't need an API key, just install it locally
# Install Ollama: https://ollama.ai/download
# Then run: ollama pull llama3.2